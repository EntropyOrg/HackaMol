{
 "metadata": {
  "language": "Perl",
  "name": "",
  "signature": "sha256:ec7082b52d242f5808ce458cc4166c7de8f3a7a0a13bf986b8bf66c0baa25e79"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##IPerl Notebook implementation of the Gaussian Network Model in Support of: \n",
      "###HackaMol: an object-oriented Modern Perl library for molecular hacking on multiple scales\n",
      "Demian Riccardi, Jerry M. Parks, Alex Johs, and Jeremy C. Smith\n",
      "\n",
      "\n",
      "####Description\n",
      "This notebook implements the [Gaussian Network Model (GNM) of Bahar, Atilgan, and Erman](http://www.sciencedirect.com/science/article/pii/S1359027897000242) using HackaMol and the Perl Data Language (PDL) and compares the calculated fluctuations to the crystallographic B-Factors. GNM simplification of the [Elastic Network Model introduced by Tirion](http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.77.1905), which was already a drastic simplification of protein dynamics.  This notebook uses the iPerl kernel, written by Zaki Mughal, of the iPython notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "use Modern::Perl;\n",
      "use HackaMol;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####1. Download molecule from Protein DataBank and read it into a HackaMol::Molecule object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "use LWP::Simple;\n",
      "my $pdb = \"2cba.pdb\"; #NMR structure with several models\n",
      "my $fpdb = getstore(\"http://pdb.org/pdb/files/$pdb\",\"$pdb\");\n",
      "\n",
      "my $mol = HackaMol->new\n",
      "                  ->read_file_mol($pdb); # object methods chain from left to right\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "HackaMol::Molecule=HASH(0x7ffab60fe338)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####2. Coarse-grain the molecule\n",
      "GNM uses the C$_\\alpha$ atoms of the protein backbone. Let's pull out those with full occupancy and create a new molecular object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my $mol_CA = HackaMol::Molecule->new(\n",
      "                                     atoms => [\n",
      "                                               grep{ $_->occ == 1.0 }\n",
      "                                               grep{ $_->name eq 'CA' } $mol->all_atoms\n",
      "                                     ]\n",
      ");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "HackaMol::Molecule=HASH(0x7ffab1ee7e50)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####4. Next, calculate a Kirchoff matrix using a single parameter: the cutoff distance\n",
      "The Kirchoff matrix (K) (also referred to as the connectivity matrix) is simple to implement. It is a square matrix with each dimension being the number of atoms, i.e. K(1:N,1:N). The cutoff distance is the parameter that determines whether or not two atoms are connected.  If the cutoff distance is small, the matrix is sparse (most elements are zero). The elements of matrix are evaluated as follows:\n",
      "\n",
      "$ K = \\left\\{ \n",
      "\\begin{array}{l l}\n",
      "  -1                 &                                                  \\quad \\mbox{if $i\\ne j$ and $R_{ij} \\le R_{cut} $}\\\\\n",
      "                   0 &                                                  \\quad \\mbox{if $R_{ij} > R_{cut} $}\\\\ \n",
      " - \\displaystyle \\sum_{i,j\\ne i} K_{ij} & \\quad  \\mbox{if $i = j$}  \n",
      " \\end{array} \\right. $\n",
      "\n",
      "Below, we define the cutoff distance, square it (to avoid calculating the square root), and then loop over the atomic coordinates to construct the matrix.      "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my $rcut  = 7.5;\n",
      "my $rsqr  = $rcut*$rcut;\n",
      "\n",
      "my $N     = $mol_CA->count_atoms;\n",
      "my @xyzs  = map{ $_->xyz } $mol_CA->all_atoms ;\n",
      "\n",
      "my @K; # Kirchoff matrix\n",
      "\n",
      "foreach my $i (0 .. $#xyzs){\n",
      "    my $xyz_i = $xyzs[$i];\n",
      "    foreach my $j ($i+1 .. $#xyzs){\n",
      "        my $dxyz2 = $xyzs[$j]->dist2($xyz_i);\n",
      "        if ($dxyz2 <= $rsqr){\n",
      "            $K[$i][$j]--;\n",
      "            $K[$j][$i]--;\n",
      "            $K[$i][$i]++;\n",
      "            $K[$j][$j]++;\n",
      "        }\n",
      "    }\n",
      "}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####5. Compute the pseudo-inverse of the Kirchoff matrix.\n",
      "Here, we use PDL and a PDL interface to Lapack (PDL::LinearAlgebra).  Since the  first eigenvalue of the Kirchoff matrix is zero, we calculate the pseudoinverse (using the mpinv function). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "use PDL::Lite;\n",
      "use PDL::Stats::Basic;\n",
      "use PDL::LinearAlgebra;\n",
      "\n",
      "my $kirch_pdl  = pdl(@K);\n",
      "my $pinv_kirch = mpinv($kirch_pdl);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "TOO LONG TO PRINT\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####6. Analyze the results\n",
      "The fluctuations in the atomic coordinates are proportional to the B-factors determined during the refinement of X-ray crystal structures. The  fluctuations predicted by GNM are the diagonal elements of the pseudoinverse of the Kirchoff matrix.  Let's compare the two. First using the Pearson correlation coefficient:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my $bfact_calc = diag($pinv_kirch);\n",
      "my $bfact_exp  = pdl(map {$_->bfact} $mol_CA->all_atoms);\n",
      "\n",
      "printf (\"Pearson coefficient: %.3f\\n\", $bfact_calc->corr($bfact_exp));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Pearson coefficient: 0.731\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next scale the calculated fluctuations so that the averages match and then print them out:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "$bfact_calc = $bfact_exp->avg*$bfact_calc/$bfact_calc->avg;\n",
      "printf(\"%10.3f %10.3f\\n\",$bfact_exp->at($_), $bfact_calc->at($_) ) foreach (0 .. $N-1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "    21.110     30.812\n",
        "    13.740     19.298\n",
        "    10.510     15.476\n",
        "    11.880     13.308\n",
        "    18.310     20.693\n",
        "    22.880     23.133\n",
        "    19.110     26.947\n",
        "    13.760     14.904\n",
        "    11.930     14.563\n",
        "    11.030     14.384\n",
        "    10.720     19.968\n",
        "     9.330     16.509\n",
        "     9.580     12.500\n",
        "    10.770     12.812\n",
        "    11.630     17.806\n",
        "    13.370     19.890\n",
        "    12.320     11.739\n",
        "    12.090     15.622\n",
        "    11.140     12.601\n",
        "    10.100     11.777\n",
        "    13.480     13.877\n",
        "    14.240     14.621\n",
        "    14.010     14.473\n",
        "     8.980      8.896\n",
        "     5.780      7.420\n",
        "     5.390      8.384\n",
        "     5.430      7.916\n",
        "     5.400      8.815\n",
        "     7.530      9.366\n",
        "     9.820      9.336\n",
        "    12.390     12.579\n",
        "    13.540     14.019\n",
        "    17.240     21.917\n",
        "    19.110     18.145\n",
        "    15.530      9.379\n",
        "    16.840     11.419\n",
        "    18.230     11.185\n",
        "    22.170     12.159\n",
        "    28.470     17.814\n",
        "    28.640     21.662\n",
        "    25.540     12.963\n",
        "    24.310     14.910\n",
        "    19.910     16.059\n",
        "    16.290     11.099\n",
        "    14.870     12.272\n",
        "    16.080     12.385\n",
        "    16.580     12.462\n",
        "    15.910      9.554\n",
        "    21.340     16.669\n",
        "    18.990     14.233\n",
        "    14.100     10.050\n",
        "    11.680      9.396\n",
        "    10.820      8.197\n",
        "    10.370      9.249\n",
        "     9.550      7.930\n",
        "     7.370      7.614\n",
        "     8.210      7.611\n",
        "     7.600      6.608\n",
        "     9.960      9.288\n",
        "     9.520      9.188\n",
        "    10.220      8.623\n",
        "     7.440      7.056\n",
        "     7.010      7.914\n",
        "     7.100      7.288\n",
        "     6.900      7.373\n",
        "     6.280      7.617\n",
        "     7.910      7.279\n",
        "    10.700     10.515\n",
        "    10.960     10.146\n",
        "    17.360     20.961\n",
        "    18.090     21.173\n",
        "    20.040     12.936\n",
        "    20.230      9.512\n",
        "    14.370      8.780\n",
        "    11.660      7.860\n",
        "    10.140      7.481\n",
        "    12.420      9.046\n",
        "    13.770     11.571\n",
        "    14.410     12.553\n",
        "    14.190     16.466\n",
        "    14.430     15.950\n",
        "    21.830     15.413\n",
        "    19.830     12.287\n",
        "    13.370      9.690\n",
        "     7.240      6.743\n",
        "     6.450      6.494\n",
        "     6.370      6.297\n",
        "     5.480      7.137\n",
        "     5.250      6.905\n",
        "     4.420      6.759\n",
        "     4.230      6.706\n",
        "     4.520      7.139\n",
        "     4.060      5.615\n",
        "     5.200      6.026\n",
        "     6.160      7.144\n",
        "     9.520      8.993\n",
        "    11.290     13.073\n",
        "    11.660      9.215\n",
        "    10.890     11.290\n",
        "     7.650      7.366\n",
        "     6.790      5.375\n",
        "     5.790      5.890\n",
        "     5.340      7.237\n",
        "     4.110      8.485\n",
        "     5.000      7.353\n",
        "     7.480      9.930\n",
        "     9.810     11.946\n",
        "    11.720     14.157\n",
        "    10.310     13.625\n",
        "    10.000      7.814\n",
        "     6.670      6.075\n",
        "     7.230      5.949\n",
        "     5.540      5.798\n",
        "     5.720      5.210\n",
        "     3.290      6.097\n",
        "     4.590      6.574\n",
        "     4.860      6.609\n",
        "     4.680      6.257\n",
        "     5.270      6.072\n",
        "     4.940      6.481\n",
        "     6.850      7.119\n",
        "    10.140      9.414\n",
        "    13.730     20.120\n",
        "    11.560     12.095\n",
        "    11.360     15.836\n",
        "    10.600     14.034\n",
        "     9.410     13.510\n",
        "     9.610     15.308\n",
        "     9.420     11.771\n",
        "     9.040      8.777\n",
        "     9.810      9.597\n",
        "    10.560     10.377\n",
        "    11.700     11.173\n",
        "    11.860     11.578\n",
        "    10.360      9.980\n",
        "     6.020      7.252\n",
        "     4.610      6.039\n",
        "     5.660      6.361\n",
        "     5.910      6.243\n",
        "     5.480      6.762\n",
        "     5.330      6.169\n",
        "     5.000      6.716\n",
        "     6.350      6.363\n",
        "     5.810      6.182\n",
        "    10.110      7.393\n",
        "    12.210      8.852\n",
        "    14.210     11.536\n",
        "    15.580     12.933\n",
        "    13.630     11.870\n",
        "    13.670     10.949\n",
        "    15.160     17.505\n",
        "    12.930     13.793\n",
        "    11.770     11.682\n",
        "    12.030     13.243\n",
        "    13.450     14.540\n",
        "    10.680     14.411\n",
        "    12.100     10.637\n",
        "    14.580     14.467\n",
        "    14.060     12.808\n",
        "    12.680     10.242\n",
        "    18.750     15.051\n",
        "    15.440     14.441\n",
        "    11.660      8.839\n",
        "    10.840      9.414\n",
        "     9.510      8.322\n",
        "    10.640      8.827\n",
        "    11.160     10.069\n",
        "    11.730      9.936\n",
        "    12.790      9.744\n",
        "    13.070      9.824\n",
        "    15.190     12.208\n",
        "    12.170     10.433\n",
        "    11.270     11.619\n",
        "    10.920     14.452\n",
        "     8.680     12.836\n",
        "     9.200     14.524\n",
        "    10.130     14.624\n",
        "    10.500     14.829\n",
        "    10.870     13.428\n",
        "    11.770     13.039\n",
        "    11.620     14.218\n",
        "     9.850     11.068\n",
        "    13.260     20.487\n",
        "    11.890     16.685\n",
        "    10.490     11.784\n",
        "     9.530      9.617\n",
        "     6.930      7.957\n",
        "     4.930      7.299\n",
        "     5.250      7.448\n",
        "     4.750      7.480\n",
        "     5.390      8.549\n",
        "     4.390      6.936\n",
        "     5.790      7.406\n",
        "     4.230      8.068\n",
        "     4.190     10.625\n",
        "     5.600     17.191\n",
        "     7.890     14.984\n",
        "     9.010     14.808\n",
        "     6.220      8.723\n",
        "     7.510      9.505\n",
        "     5.790      8.479\n",
        "     6.230      6.659\n",
        "     5.840      6.101\n",
        "     4.770      6.593\n",
        "     6.090      6.488\n",
        "     6.090      6.568\n",
        "     7.000      7.782\n",
        "     6.810      6.895\n",
        "     9.610     11.018\n",
        "     8.330     10.037\n",
        "     9.510      7.844\n",
        "    10.090      7.947\n",
        "    13.010      8.530\n",
        "    12.330      7.956\n",
        "    12.590      9.687\n",
        "    13.450     11.933\n",
        "    13.810     15.132\n",
        "    11.120     10.328\n",
        "    13.180     11.103\n",
        "    15.360     12.189\n",
        "    13.000     10.854\n",
        "     9.940     11.549\n",
        "     9.880      9.083\n",
        "    11.560     11.080\n",
        "     9.650      9.155\n",
        "    10.410      8.787\n",
        "    10.490      9.156\n",
        "    13.070     10.914\n",
        "    16.030     13.296\n",
        "    18.800     16.780\n",
        "    24.110     24.477\n",
        "    24.630     18.503\n",
        "    21.740     20.416\n",
        "    18.430     16.372\n",
        "    15.140     13.667\n",
        "     9.890     10.280\n",
        "     7.550      7.428\n",
        "     7.360      9.554\n",
        "     5.250      7.795\n",
        "     5.840      6.469\n",
        "     6.700      8.444\n",
        "     7.620      9.548\n",
        "    10.960     12.707\n",
        "     9.250      8.111\n",
        "     8.930     10.619\n",
        "    12.230     13.539\n",
        "    13.120     12.564\n",
        "    17.000     14.725\n",
        "    22.270     16.880\n",
        "    15.510     12.027\n",
        "    16.610     11.949\n",
        "    11.560      8.765\n",
        "    10.960      8.630\n",
        "    10.100      8.510\n",
        "    12.760      9.285\n",
        "    19.010     14.338\n",
        "    30.790     20.286\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####TODO: Analyze the atom-atom correlations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}